# Large Transformer teacher configuration
env_id: FlyCraft-Nav-v0
run_name: teacher_large
output_dir: runs
seed: 42
n_envs: 16
max_episode_steps: 1000

policy: transformer
policy_kwargs:
  transformer_kwargs:
    embed_dim: 512
    depth: 8
    num_heads: 16
    dropout: 0.1
    memory_size: 128

ppo_kwargs:
  learning_rate: 3.0e-4
  n_steps: 2048
  batch_size: 4096
  n_epochs: 4
  gamma: 0.995
  gae_lambda: 0.95
  clip_range: 0.2

timesteps: 5000000
save_freq: 50000
eval_freq: 20000
n_eval_episodes: 10

use_spatio_temporal: true
predict_sequence: true
prediction_horizon: 200
eval:
  # primary thresholds
  ttc: 3.0                 # seconds
  path_dev: 0.5            # meters
  completion: 60.0         # seconds
  latency: 10.0            # ms
  goal_radius: 0.6         # a bit looser than 0.5

  # tolerances for path deviation
  path_dev_tol_pct: 0.10   # +10% cushion (set 0.05 for +5%)
  path_dev_tol_abs: 0.00

  # tolerant numeric compare (only used if you provide predictions/targets in episode_data)
  success_atol: 0.0
  success_rtol: 0.05       # 5% relative window
  success_reduce: "all"    # 'all' or 'any' across dims
  success_min_frac: 1.0    # require 100% of dims to be “close” (lower to 0.5 if needed)
